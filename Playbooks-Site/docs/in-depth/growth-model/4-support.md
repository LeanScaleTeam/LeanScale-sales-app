---
displayed_sidebar: inDepthSidebar
title: "Growth Model Post Support"
sidebar_position: 4
---

# Growth Model Support

Dependencies & Inputs - Common Pitfalls - Success Metrics - Maintenance

## Dependencies & Inputs

### What Must Exist Before Starting

- **CRM access** with at least 12 months of closed-won deal data (ideally 18-24 months for trend analysis)
- **Clear top-down ARR targets** (board-level or exec-level) with quarterly breakdown
- **Access to key stakeholder** (CRO, VP Sales, or RevOps lead) for validation
- **Understanding of current pricing/ACV structure** and any planned pricing changes
- **Customer data to calculate NRR** (expansion, contraction, churn by cohort)

---
displayed_sidebar: inDepthSidebar

### What Client Must Provide

| Input | Who Provides | Why Needed |
|-------|--------------|------------|
| CRM admin access or exported deal data with stage history | RevOps | Extract historical performance |
| Board deck or exec targets for ARR goals | CRO/VP Sales | Establish targets |
| 30-60 min kickoff call with revenue leader | CRO/VP Sales | Align on context and priorities |
| Clarity on segments (enterprise vs SMB vs mid-market) | RevOps | Define segment breakdown |
| Historical NRR data or access to billing system | Finance/RevOps | Calculate retention metrics |

### What LeanScale Brings

- Industry benchmark data (KeyBanc, OpenView, Bessemer)
- Power 10 framework and model templates
- GTM expertise to identify gaps and prioritize based on ROI of improvement
- Scenario modeling methodology

---
displayed_sidebar: inDepthSidebar

## Common Pitfalls

### Pitfall 1: Applying Single Growth Rate Across All Segments

**Problem:** Using one blended growth rate masks the reality that Enterprise, Mid-Market, and SMB have fundamentally different conversion rates, sales cycles, and ACVs.

**Reality:** Enterprise might have 15% win rate with 6-month cycle and $200k ACV. SMB might have 30% win rate with 2-week cycle and $5k ACV. Blending these creates meaningless averages.

**Mitigation:** Break out model by segment from the start. Model capacity needs per segment. Let each segment's unique dynamics inform the forecast.

---
displayed_sidebar: inDepthSidebar

### Pitfall 2: Ignoring Churn and Contraction

**Problem:** Focusing only on new ARR and ignoring retention leads to overstated net growth projections.

**Reality:** A company adding $1M new ARR but churning $400k is only netting $600k. If churn accelerates, you can be "growing" while actually shrinking net.

**Mitigation:** Explicitly model Net Revenue Retention with separate lines for expansion, contraction, and churn. Treat retention and expansion as part of pipeline forecasts, not afterthoughts.

---
displayed_sidebar: inDepthSidebar

### Pitfall 3: Building a Model Too Complex to Maintain

**Problem:** Creating an elaborate model that requires a PhD to update leads to abandonment within 2 months.

**Reality:** RevOps has limited time. If updates take more than 2 hours monthly, the model becomes shelfware.

**Mitigation:** Focus on the 7-10 key drivers that create 80% of impact (the Power 10 framework). Client RevOps must be able to update it in 2 hours or less per month. Complexity is the enemy of maintenance.

---
displayed_sidebar: inDepthSidebar

### Pitfall 4: Validating Only Against Historical Trends

**Problem:** Assuming "we grew 20% last quarter, so we'll grow 20% next quarter" without validating against current pipeline reality.

**Reality:** Historical performance doesn't guarantee future results. Pipeline coverage might be at 1.5x instead of the 3x needed for that growth rate.

**Mitigation:** Cross-reference bottoms-up forecast against current weighted pipeline to ensure targets are feasible, not aspirational. Adjust if pipeline coverage is below 3x. Red-flag quarters where math doesn't work.

---
displayed_sidebar: inDepthSidebar

### Pitfall 5: Over-Relying on Automation Without Human Judgment

**Problem:** Trusting AI-generated forecasts or automated models without sales leader overlay leads to "garbage in, garbage out."

**Reality:** Models miss context: a key competitor just launched, your best rep is leaving, or a whale deal will close next week.

**Mitigation:** Use predictive analytics to inform decisions, but balance with sales leader intuition and market knowledge. Regular review sessions where leaders can adjust AI-generated insights. Model is a starting point, not gospel.

---
displayed_sidebar: inDepthSidebar

## Success Metrics

### Leading Indicators

| Metric | Target | Timeline |
|--------|--------|----------|
| Model walkthrough completed with RevOps/Finance | Yes | Project close |
| Client can articulate top 2-3 gaps | Yes, with dollar impact | Handoff meeting |
| Model owner identified and trained | Yes | Project close |
| First monthly update completed independently | Within 2 hours | 30 days post-handoff |

---
displayed_sidebar: inDepthSidebar

### Lagging Indicators

| Metric | Target | Timeline |
|--------|--------|----------|
| Quarterly actuals track within 10% of model projections | Yes | After 1 quarter |
| Model used in board meeting or QBR | Yes | Next board cycle |
| Resource allocation decisions reference model | Yes | Next planning cycle |
| Model updated monthly | Yes | Ongoing |

---
displayed_sidebar: inDepthSidebar

### How to Measure Success

**Short-term (30 days):**
- Can client update the model independently?
- Does client understand the top gaps and their dollar impact?
- Is the model owner confident in the mechanics?

**Medium-term (90 days):**
- Has the model informed any resource decisions?
- Are actuals tracking within range of projections?
- Is the model being updated monthly?

**Long-term (6+ months):**
- Is the model a standard part of board/QBR preparation?
- Has gap analysis led to any improvement initiatives?
- Are forecasts more accurate than before the model?

---
displayed_sidebar: inDepthSidebar

## Maintenance Schedule

### Monthly Tasks (2 hours or less)

| Task | Owner | Time Required |
|------|-------|---------------|
| Update actual closed-won data for prior month | RevOps | 30 min |
| Update pipeline data for coverage calculation | RevOps | 30 min |
| Refresh ARR momentum table with actuals | RevOps | 15 min |
| Compare actuals to forecast and note variances | RevOps | 30 min |
| Adjust forward assumptions if needed | RevOps | 15 min |

---
displayed_sidebar: inDepthSidebar

### Quarterly Tasks

| Task | Owner | Time Required |
|------|-------|---------------|
| Full model review with VP Sales/CRO | RevOps + Sales | 1 hour |
| Update benchmark comparisons | RevOps | 30 min |
| Refresh scenario models | RevOps | 1 hour |
| Gap analysis refresh and prioritization | RevOps + Sales | 1 hour |
| Board deck preparation with model insights | RevOps + Finance | 2 hours |

---
displayed_sidebar: inDepthSidebar

### Annual Tasks

| Task | Owner | Time Required |
|------|-------|---------------|
| Full model rebuild with new year targets | RevOps | 4-8 hours |
| Refresh all benchmarks for new year | RevOps | 2 hours |
| Review and update segment definitions | RevOps + Sales | 1 hour |
| Recalibrate conversion rates with full year data | RevOps | 2 hours |

---
displayed_sidebar: inDepthSidebar

## Troubleshooting Guide

### Common Issues and Resolutions

| Issue | Likely Cause | Resolution |
|-------|--------------|------------|
| Actuals consistently below forecast | Win rate or pipeline coverage assumptions too aggressive | Re-baseline assumptions with recent data |
| Capacity model shows no gap but targets missed | Attainment assumption too high | Use 70-75% attainment instead of 100% |
| NRR trending down unexpectedly | Churn or contraction underestimated | Audit customer health data, adjust assumptions |
| Model takes too long to update | Too many inputs or complexity | Simplify to core Power 10 metrics |
| Stakeholders don't trust the model | Assumptions not validated with them | Schedule review session, get sign-off on inputs |
| Pipeline coverage looks healthy but deals slip | Pipeline quality issue | Add stage-weighted or recency-weighted calculation |

---
displayed_sidebar: inDepthSidebar

## Related Projects

### Downstream Projects (Informed by Growth Model)

| Project | Relationship |
|---------|--------------|
| **Territory Design** | Uses capacity model outputs for rep allocation |
| **Quota Setting** | Uses productivity and capacity assumptions |
| **Sales Process Optimization** | Addresses conversion rate gaps identified |
| **Lead Generation Strategy** | Addresses volume gaps identified |
| **Comp Plan Design** | Uses productivity benchmarks |

### Upstream Dependencies

| Project | Relationship |
|---------|--------------|
| **CRM Data Quality** | Model accuracy depends on clean data |
| **Lead Lifecycle Definition** | Conversion metrics require clear stage definitions |
| **Pricing Strategy** | ACV assumptions depend on pricing clarity |

---
displayed_sidebar: inDepthSidebar

## Final Deliverables Checklist

### Model Files
- [ ] Complete spreadsheet with all tabs (Inputs, Model, ARR Momentum, Capacity, Scenarios, Dashboard)
- [ ] All input cells documented with sources
- [ ] Formulas commented where complex
- [ ] Executive summary view for board reporting

### Documentation
- [ ] Model user guide
- [ ] Input source documentation
- [ ] Monthly update SOP
- [ ] Assumptions log with validation notes

### Training
- [ ] 60-min training session completed
- [ ] Quick-reference guide delivered
- [ ] First update cycle practiced together

### Handoff
- [ ] Model owner identified and trained
- [ ] Stakeholder presentation delivered
- [ ] Gap analysis reviewed with leadership
- [ ] 30-day check-in scheduled
